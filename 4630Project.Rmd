---
title: "STAT 4630 Project"
output: html_document
date: "2025-11-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Setup by downloading all needed packages
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(glmnet)
library(ranger)
library(pROC)
library(Matrix)
library(xgboost)
library(corrplot)

set.seed(123)
```
### EDA and Processing ###
```{r}
# Loading data and calculating basic outcomes
metabric <- read.csv("METABRIC_RNA_Mutation.csv",
                     stringsAsFactors = FALSE)

# Binary outcome: 0 = Deceased, 1 = Alive
outcome_col <- "overall_survival"
time_col    <- "overall_survival_months"

metabric[[outcome_col]] <- as.integer(metabric[[outcome_col]])

# Keep only rows with non-missing survival + time
metabric <- metabric %>%
  filter(!is.na(.data[[outcome_col]]),
         !is.na(.data[[time_col]]))

# Outcome vector (0/1)
y_bin <- metabric[[outcome_col]]
table(y_bin)
prop.table(table(y_bin))

# Identify putative gene columns vs clinical columns
is_gene_col   <- grepl("^[a-z0-9]+$", names(metabric))
clinical_vars <- names(metabric)[!is_gene_col]
mutation_vars <- names(metabric)[is_gene_col]

length(clinical_vars)
length(mutation_vars)
```

```{r}
# EDA with class imbalance
ggplot(metabric, aes(x = factor(.data[[outcome_col]]))) +
  geom_bar(fill = "#4C72B0") +
  labs(
    title = "Class Distribution: Overall Survival",
    x = "Overall Survival (0 = Deceased, 1 = Alive)",
    y = "Count"
  ) +
  theme_minimal()

# EDA with clinical variables and identifying missingness
clinical_predictors <- setdiff(
  clinical_vars,
  c("patient_id", outcome_col, time_col, "death_from_cancer", "cancer_type")
)
clinical_predictors <- intersect(clinical_predictors, names(metabric))

missing_clin <- sapply(
  metabric[, clinical_predictors, drop = FALSE],
  function(x) mean(is.na(x))
)

missing_clin_df <- data.frame(
  variable     = names(missing_clin),
  missing_prop = as.numeric(missing_clin),
  row.names    = NULL
)

top_missing <- missing_clin_df %>%
  arrange(desc(missing_prop)) %>%
  head(10)

top_missing

ggplot(top_missing, aes(x = reorder(variable, missing_prop),
                        y = missing_prop)) +
  geom_col(fill = "#DD8452") +
  coord_flip() +
  labs(
    title = "Top 10 Clinical Variables by Missingness",
    x = "Variable",
    y = "Proportion Missing"
  ) +
  theme_minimal()

# EDA with mutation sparsity
mut_mat_full <- as.matrix(metabric[, mutation_vars, drop = FALSE])
mut_nonzero_prop <- colMeans(mut_mat_full != 0, na.rm = TRUE)

summary(mut_nonzero_prop)

mut_prop_df <- data.frame(
  nonzero_prop = mut_nonzero_prop
)

ggplot(mut_prop_df, aes(x = nonzero_prop)) +
  geom_histogram(bins = 40, fill = "#4C72B0", color = "white") +
  labs(
    title = "Non-zero Proportion Across Mutation Features",
    x = "Proportion of Samples with Non-zero Mutation Indicator",
    y = "Number of Genes"
  ) +
  theme_minimal()

# EDA with correlation among numerical clinical variables
num_clinical_vars <- clinical_predictors[
  sapply(metabric[, clinical_predictors, drop = FALSE], is.numeric)
]

length(num_clinical_vars)

cor_mat <- cor(
  metabric[, num_clinical_vars, drop = FALSE],
  use = "pairwise.complete.obs"
)

corrplot(
  cor_mat,
  method = "color",
  type = "upper",
  tl.cex = 0.6,
  tl.col = "black",
  diag = FALSE
)
```

```{r}
# EDA with Mutation Burden
metabric$mutation_count_raw <- rowSums(mut_mat_full != 0, na.rm = TRUE)

ggplot(metabric, aes(x = mutation_count_raw)) +
  geom_histogram(bins = 35, fill = "#4C72B0", color = "white") +
  labs(
    title = "Distribution of Mutation Burden per Patient",
    x = "Number of Mutated Genes",
    y = "Number of Patients"
  ) +
  theme_minimal()
```


```{r}
# Build long-format data for density plots
metabric_long <- metabric %>%
  dplyr::select(overall_survival, all_of(num_clinical_vars)) %>%
  tidyr::pivot_longer(
    cols      = -overall_survival,
    names_to  = "variable",
    values_to = "value"
  ) %>%
  dplyr::filter(!is.na(value))
```

```{r density_plots, fig.width=14, fig.height=10}
ggplot(metabric_long, aes(x = value, fill = factor(overall_survival))) +
  geom_density(alpha = 0.4) +
  facet_wrap(~ variable, scales = "free") +
  scale_fill_manual(values = c("#DD8452", "#4C72B0")) +
  labs(
    title = "Density Plots by Survival Outcome",
    x = "Value",
    fill = "Outcome"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.text.x = element_text(size = 8),
    axis.text.y = element_text(size = 8)
  )


```

```{r}

# EDA with Stacked Chart
cat_var <- "tumor_stage"   

ggplot(metabric, aes(x = .data[[cat_var]], fill = factor(.data[[outcome_col]]))) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(values = c("#DD8452", "#4C72B0")) +
  labs(
    title = paste("Survival Proportion by", cat_var),
    x = cat_var, y = "Proportion Alive"
  ) +
  theme_minimal()


```

```{r}

# EDA: Boxplots of Key Predictors vs Outcome


key_continuous <- c(
  "age_at_diagnosis",
  "tumor_size",
  "lymph_nodes_examined_positive",
  "nottingham_prognostic_index"
)

# Keep only predictors that actually exist in metabric
key_continuous <- intersect(key_continuous, names(metabric))

metabric_box_long <- metabric %>%
  dplyr::select(all_of(c(outcome_col, key_continuous))) %>%
  tidyr::pivot_longer(
    cols = all_of(key_continuous),
    names_to = "variable",
    values_to = "value"
  )

ggplot(
  metabric_box_long,
  aes(x = factor(.data[[outcome_col]]), y = value)
) +
  geom_boxplot(fill = "#4C72B0", alpha = 0.7, outlier.alpha = 0.6) +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    title = "Boxplots of Key Clinical Predictors by Survival Outcome",
    x = "Overall Survival (0 = Deceased, 1 = Alive)",
    y = "Value"
  ) +
  theme_minimal()


```

```{r}
# -----------------------------------
# EDA: Scatterplots with Outcome
# -----------------------------------

if (all(c("neoplasm_histologic_grade", "nottingham_prognostic_index") %in% names(metabric))) {
  ggplot(
    metabric,
    aes(
      x = neoplasm_histologic_grade,
      y = nottingham_prognostic_index
    )
  ) +
    geom_point(alpha = 0.55, color = "#4C72B0") +
    geom_smooth(method = "loess", se = FALSE, color = "#DD8452") +
    labs(
      title = "Neoplasm Histologic Grade vs Nottingham Prognostic Index",
      x = "Histologic Grade",
      y = "Nottingham Prognostic Index"
    ) +
    theme_minimal()
}




```

```{r}
if (all(c("lymph_nodes_examined_positive", "nottingham_prognostic_index") %in% names(metabric))) {
  ggplot(
    metabric,
    aes(
      x = lymph_nodes_examined_positive,
      y = nottingham_prognostic_index
    )
  ) +
    geom_point(alpha = 0.55, color = "#4C72B0") +
    geom_smooth(method = "loess", se = FALSE, color = "#DD8452") +
    labs(
      title = "Lymph Nodes Examined Positive vs Nottingham Prognostic Index",
      x = "Lymph Nodes Examined Positive",
      y = "Nottingham Prognostic Index"
    ) +
    theme_minimal()
}

```
```{r}
if (all(c("tumor_size", "tumor_stage") %in% names(metabric))) {
  
  # convert tumor_stage to numeric if needed
  if (!is.numeric(metabric$tumor_stage)) {
    metabric$tumor_stage_numeric <- as.numeric(metabric$tumor_stage)
  } else {
    metabric$tumor_stage_numeric <- metabric$tumor_stage
  }
  
  ggplot(
    metabric,
    aes(
      x = tumor_size,
      y = tumor_stage_numeric
    )
  ) +
    geom_point(alpha = 0.55, color = "#4C72B0") +
    geom_smooth(method = "loess", se = FALSE, color = "#DD8452") +
    labs(
      title = "Tumor Size vs Tumor Stage",
      x = "Tumor Size",
      y = "Tumor Stage (numeric)"
    ) +
    theme_minimal()
}

```
```{r}
if (all(c("nottingham_prognostic_index", "tumor_stage") %in% names(metabric))) {
  
  if (!is.numeric(metabric$tumor_stage)) {
    metabric$tumor_stage_numeric <- as.numeric(metabric$tumor_stage)
  }
  
  ggplot(
    metabric,
    aes(
      x = nottingham_prognostic_index,
      y = tumor_stage_numeric
    )
  ) +
    geom_point(alpha = 0.55, color = "#4C72B0") +
    geom_smooth(method = "loess", se = FALSE, color = "#DD8452") +
    labs(
      title = "Nottingham Prognostic Index vs Tumor Stage",
      x = "Nottingham Prognostic Index",
      y = "Tumor Stage (numeric)"
    ) +
    theme_minimal()
}

```
```{r}
if (all(c("lymph_nodes_examined_positive", "tumor_stage") %in% names(metabric))) {
  
  if (!is.numeric(metabric$tumor_stage)) {
    metabric$tumor_stage_numeric <- as.numeric(metabric$tumor_stage)
  }
  
  ggplot(
    metabric,
    aes(
      x = lymph_nodes_examined_positive,
      y = tumor_stage_numeric
    )
  ) +
    geom_point(alpha = 0.55, color = "#4C72B0") +
    geom_smooth(method = "loess", se = FALSE, color = "#DD8452") +
    labs(
      title = "Lymph Nodes Examined Positive vs Tumor Stage",
      x = "Lymph Nodes Examined Positive",
      y = "Tumor Stage (numeric)"
    ) +
    theme_minimal()
}

```

```{R}
vars_to_check <- c(
  "neoplasm_histologic_grade",
  "nottingham_prognostic_index",
  "lymph_nodes_examined_positive",
  "tumor_size",
  "tumor_stage",
  "age_at_diagnosis"
)
vars_to_check <- intersect(vars_to_check, names(metabric))
vars_to_check
cor_mat <- cor(
  metabric[, vars_to_check, drop = FALSE],
  use = "pairwise.complete.obs",
  method = "pearson"
)

cor_mat

```


```{r}
# -----------------------------------
# EDA: Outlier Check for Numeric Clinical Variables
# -----------------------------------


num_clin_df <- metabric[, num_clinical_vars, drop = FALSE]

outlier_summary <- apply(
  num_clin_df,
  2,
  function(x) {
    x <- x[!is.na(x)]
    
    vals <- c(
      quantile(x, 0.01),
      quantile(x, 0.25),
      median(x),
      quantile(x, 0.75),
      quantile(x, 0.99),
      max(x)
    )
    
    # Clean, explicit names
    names(vals) <- c("p01", "p25", "median", "p75", "p99", "max")
    vals
  }
)

outlier_summary <- as.data.frame(t(outlier_summary))
outlier_summary$variable <- rownames(outlier_summary)
rownames(outlier_summary) <- NULL

outlier_summary <- outlier_summary %>%
  dplyr::mutate(
    extreme_ratio = .data[["max"]] / .data[["p99"]]
  ) %>%
  dplyr::arrange(dplyr::desc(extreme_ratio))

head(outlier_summary, 15)


```
```{r}
library(dplyr)

# Thresholds from outlier_summary

p01_ts <- outlier_summary %>%
filter(variable == "tumor_size") %>%
pull(p01)

p99_ts <- outlier_summary %>%
filter(variable == "tumor_size") %>%
pull(p99)

p01_ln <- outlier_summary %>%
filter(variable == "lymph_nodes_examined_positive") %>%
pull(p01)

p99_ln <- outlier_summary %>%
filter(variable == "lymph_nodes_examined_positive") %>%
pull(p99)

# Cleaned dataset with quantile + hard caps

metabric_clean <- metabric %>%
filter(
tumor_size >= p01_ts,
tumor_size <= min(p99_ts, 150),
lymph_nodes_examined_positive >= p01_ln,
lymph_nodes_examined_positive <= min(p99_ln, 20)
)

# Binary outcome from cleaned data

y_bin <- metabric_clean[[outcome_col]]
table(y_bin)


```

```{r}
# Recompute gene sparsity on cleaned data

mut_mat_full <- as.matrix(metabric_clean[, mutation_vars, drop = FALSE])
mut_nonzero_prop <- colMeans(mut_mat_full != 0, na.rm = TRUE)

low_info_thresh <- 0.01
keep_genes <- names(mut_nonzero_prop[mut_nonzero_prop >= low_info_thresh])
drop_genes <- setdiff(mutation_vars, keep_genes)

length(mutation_vars)  # original
length(keep_genes)     # kept

mutation_vars <- keep_genes

# Define predictor set: drop composite/treatment/leakage variables

exclude_vars <- c(
"patient_id",
outcome_col,
time_col,
"death_from_cancer",
"cancer_type",
"nottingham_prognostic_index",
"tumor_stage",
"mutation_count",
"hormone_therapy",
"radio_therapy",
drop_genes
)

exclude_vars <- intersect(exclude_vars, names(metabric_clean))

predictor_vars <- setdiff(names(metabric_clean), exclude_vars)
length(predictor_vars)


```
```{r}
library(caret)
set.seed(123)

train_idx <- createDataPartition(y_bin, p = 0.7, list = FALSE)

train_dat <- metabric_clean[train_idx, ]
test_dat  <- metabric_clean[-train_idx, ]

y_train_bin <- train_dat[[outcome_col]]
y_test_bin  <- test_dat[[outcome_col]]

# Preprocessing function: factors, Missing level, rare levels

prep_predictors <- function(df, vars, min_count = 20) {
preds <- df[, vars, drop = FALSE]

# Characters: "" -> NA, then factor

char_cols <- sapply(preds, is.character)
preds[char_cols] <- lapply(preds[char_cols], function(x) {
x[x == ""] <- NA
x
})
preds[char_cols] <- lapply(preds[char_cols], factor)

# Add "Missing" level to all factors

make_missing_level <- function(f) {
f <- addNA(f)
lev <- levels(f)
lev[is.na(lev)] <- "Missing"
levels(f) <- lev
f
}
fac_cols <- sapply(preds, is.factor)
preds[fac_cols] <- lapply(preds[fac_cols], make_missing_level)

# Merge rare levels into "Other"

merge_rare_levels <- function(f, min_count = 20) {
tab <- table(f)
rare_levels <- names(tab[tab < min_count])
if (length(rare_levels) > 0) {
f <- factor(ifelse(f %in% rare_levels, "Other", as.character(f)))
} else {
f <- factor(f)
}
f
}
preds[fac_cols] <- lapply(preds[fac_cols], merge_rare_levels, min_count = min_count)

preds
}

predictors_all <- prep_predictors(metabric_clean, predictor_vars, min_count = 20)

predictors_train <- predictors_all[train_idx, , drop = FALSE]
predictors_test  <- predictors_all[-train_idx, , drop = FALSE]

```

```{r}
num_cols <- sapply(predictors_train, is.numeric)

pre_num <- preProcess(
predictors_train[, num_cols, drop = FALSE],
method = c("medianImpute")
)

num_train_imp <- predict(pre_num, predictors_train[, num_cols, drop = FALSE])
num_test_imp  <- predict(pre_num, predictors_test[,  num_cols, drop = FALSE])

predictors_train_clean <- data.frame(
num_train_imp,
predictors_train[, !num_cols, drop = FALSE]
)
predictors_test_clean <- data.frame(
num_test_imp,
predictors_test[, !num_cols, drop = FALSE]
)

nzv_idx <- nearZeroVar(predictors_train_clean)
if (length(nzv_idx) > 0) {
predictors_train_clean <- predictors_train_clean[, -nzv_idx, drop = FALSE]
predictors_test_clean  <- predictors_test_clean[,  -nzv_idx, drop = FALSE]
}

dim(predictors_train_clean)
dim(predictors_test_clean)

```
```{r}
# Mutation gene columns present after cleaning

gene_cols_in_clean <- intersect(mutation_vars, names(predictors_train_clean))

if (length(gene_cols_in_clean) > 0) {

# Keep only numeric gene columns

gene_cols_numeric <- gene_cols_in_clean[
sapply(predictors_train_clean[, gene_cols_in_clean, drop = FALSE], is.numeric)
]

if (length(gene_cols_numeric) > 0) {


gene_train_mat <- as.matrix(predictors_train_clean[, gene_cols_numeric, drop = FALSE])
gene_test_mat  <- as.matrix(predictors_test_clean[,  gene_cols_numeric, drop = FALSE])

# Drop columns with all NA or zero variance in train
drop_cols <- apply(gene_train_mat, 2, function(z) {
  all(is.na(z)) || var(z, na.rm = TRUE) == 0
})

if (any(drop_cols)) {
  gene_train_mat <- gene_train_mat[, !drop_cols, drop = FALSE]
  gene_test_mat  <- gene_test_mat[, !drop_cols, drop = FALSE]
  gene_cols_final <- gene_cols_numeric[!drop_cols]
} else {
  gene_cols_final <- gene_cols_numeric
}

if (length(gene_cols_final) == 0) {
  predictors_train_pca <- predictors_train_clean
  predictors_test_pca  <- predictors_test_clean
} else {
  # Replace NAs with 0 before PCA
  gene_train_mat[is.na(gene_train_mat)] <- 0
  gene_test_mat[is.na(gene_test_mat)]  <- 0
  
  pca_genes <- prcomp(gene_train_mat, center = TRUE, scale. = TRUE)
  
  # K PCs: min # to explain >= 80% variance, capped at 20
  pca_sum <- summary(pca_genes)
  cumvar  <- pca_sum$importance["Cumulative Proportion", ]
  K_80    <- which(cumvar >= 0.80)[1]
  if (is.na(K_80)) K_80 <- ncol(pca_genes$x)
  K <- min(K_80, 20, ncol(pca_genes$x))
  
  pc_train <- as.data.frame(pca_genes$x[, 1:K, drop = FALSE])
  
  pc_test <- as.data.frame(
    scale(
      gene_test_mat,
      center = pca_genes$center,
      scale  = pca_genes$scale
    ) %*% pca_genes$rotation[, 1:K, drop = FALSE]
  )
  
  colnames(pc_train) <- paste0("PC_gene_", seq_len(K))
  colnames(pc_test)  <- paste0("PC_gene_", seq_len(K))
  
  predictors_train_pca <- predictors_train_clean %>%
    select(-all_of(gene_cols_final)) %>%
    bind_cols(pc_train)
  
  predictors_test_pca <- predictors_test_clean %>%
    select(-all_of(gene_cols_final)) %>%
    bind_cols(pc_test)
}


} else {
# No numeric gene columns
predictors_train_pca <- predictors_train_clean
predictors_test_pca  <- predictors_test_clean
}

} else {

# No mutation gene columns

predictors_train_pca <- predictors_train_clean
predictors_test_pca  <- predictors_test_clean
}

dim(predictors_train_pca)
dim(predictors_test_pca)


```
```{r}
# Single clinically motivated interaction: tumor_size x lymph_nodes_examined_positive

make_interactions <- function(df, vars, prefix = "int_") {
out <- df
if (length(vars) == 2) {
v1 <- vars[1]
v2 <- vars[2]
inter_name <- paste0(prefix, v1, "*x*", v2)
out[[inter_name]] <- df[[v1]] * df[[v2]]
}
out
}

clin_interact_vars <- intersect(
c("tumor_size", "lymph_nodes_examined_positive"),
names(predictors_train_pca)
)

clin_interact_vars

predictors_train_final <- make_interactions(predictors_train_pca, clin_interact_vars)
predictors_test_final  <- make_interactions(predictors_test_pca,  clin_interact_vars)

dim(predictors_train_final)
dim(predictors_test_final)

```
```{r}
library(dplyr)

# PC_gene_ columns

pc_cols <- grep("^PC_gene_", names(predictors_train_final), value = TRUE)

# Keep first 5 PCs (aggressive)

pc_keep <- head(pc_cols, 5)
pc_drop <- setdiff(pc_cols, pc_keep)

# Mutation indicator columns (ending with _mut)

mut_cols <- grep("_mut$", names(predictors_train_final), value = TRUE)

# Frequency of mutations

mut_counts <- colSums(predictors_train_final[, mut_cols, drop = FALSE] == 1, na.rm = TRUE)

# Drop mutations that appear in fewer than 10 patients

mut_drop <- names(mut_counts)[mut_counts < 10]

drop_cols <- c(pc_drop, mut_drop)

predictors_train_reduced <- predictors_train_final %>%
select(-all_of(drop_cols))

predictors_test_reduced <- predictors_test_final %>%
select(-all_of(drop_cols))

dim(predictors_train_reduced)
dim(predictors_test_reduced)
length(names(predictors_train_reduced))

```

```{r}
library(Matrix)

# Model matrix (dummy-encode factors, no intercept)

pred_all_reduced <- rbind(predictors_train_reduced, predictors_test_reduced)

mm_formula <- ~ . - 1
X_all <- model.matrix(mm_formula, data = pred_all_reduced)

n_train <- nrow(predictors_train_reduced)
X_train_mat <- X_all[1:n_train, , drop = FALSE]
X_test_mat  <- X_all[(n_train + 1):nrow(X_all), , drop = FALSE]

# Optional sparse versions

X_train_sp <- as(X_train_mat, "dgCMatrix")
X_test_sp  <- as(X_test_mat,  "dgCMatrix")

# Outcomes

y_train_num <- y_train_bin
y_test_num  <- y_test_bin

y_train_fac <- factor(ifelse(y_train_bin == 1, "Yes", "No"),
levels = c("No", "Yes"))
y_test_fac  <- factor(ifelse(y_test_bin  == 1, "Yes", "No"),
levels = c("No", "Yes"))

# Macro-F1 helper

macro_f1 <- function(pred, y_true) {
pred_fac <- factor(pred, levels = c(0, 1))
y_fac    <- factor(y_true, levels = c(0, 1))

f1_pos <- F_meas(pred_fac, y_fac, relevant = "1")
f1_neg <- F_meas(pred_fac, y_fac, relevant = "0")

(f1_pos + f1_neg) / 2
}

# Total sum of squares for pseudo-R2 on test set

sst <- sum((y_test_bin - mean(y_test_bin))^2)

# Repeated CV tuned on ROC

ctrl <- trainControl(
method          = "repeatedcv",
number          = 5,
repeats         = 2,
classProbs      = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final",
verboseIter     = FALSE
)

```

```{r}
library(pROC)
library(ranger)
library(xgboost)

set.seed(123)

## ---- SVM (linear) ----

svm_grid <- expand.grid(C = c(0.25, 1, 4))

svm_fit <- train(
x          = X_train_mat,
y          = y_train_fac,
method     = "svmLinear",
trControl  = ctrl,
metric     = "ROC",
preProcess = c("center", "scale"),
tuneGrid   = svm_grid
)

prob_svm_test <- predict(svm_fit, newdata = X_test_mat, type = "prob")[, "Yes"]
pred_svm_test <- ifelse(prob_svm_test >= 0.5, 1, 0)

acc_svm <- mean(pred_svm_test == y_test_bin)
roc_svm <- roc(y_test_bin, prob_svm_test)
auc_svm <- as.numeric(auc(roc_svm))

f1_macro_svm <- macro_f1(pred_svm_test, y_test_bin)

acc_svm; auc_svm; f1_macro_svm
```

```{r}
## ---- Random Forest (ranger) ----

set.seed(123)

p <- ncol(X_train_mat)
rf_grid <- expand.grid(
mtry          = floor(c(sqrt(p), p / 4)),
splitrule     = "gini",
min.node.size = c(5, 10)
)

rf_fit <- train(
x          = X_train_mat,
y          = y_train_fac,
method     = "ranger",
trControl  = ctrl,
metric     = "ROC",
tuneGrid   = rf_grid,
num.trees  = 300,
importance = "impurity"
)

prob_rf_test <- predict(rf_fit, newdata = X_test_mat, type = "prob")[, "Yes"]
pred_rf_test <- ifelse(prob_rf_test >= 0.5, 1, 0)

acc_rf <- mean(pred_rf_test == y_test_bin)
roc_rf <- roc(y_test_bin, prob_rf_test)
auc_rf <- as.numeric(auc(roc_rf))
sse_rf <- sum((y_test_bin - prob_rf_test)^2)
f1_macro_rf <- macro_f1(pred_rf_test, y_test_bin)

acc_rf; auc_rf; f1_macro_rf
```

```{r}
## ---- XGBoost ----

set.seed(123)

xgb_grid <- expand.grid(
nrounds          = c(100, 200),
max_depth        = c(3, 4),
eta              = c(0.05, 0.10),
gamma            = 0,
colsample_bytree = 0.7,
min_child_weight = 1,
subsample        = 0.8
)

xgb_fit <- train(
x          = X_train_mat,
y          = y_train_fac,
method     = "xgbTree",
trControl  = ctrl,
metric     = "ROC",
tuneGrid   = xgb_grid
)

prob_xgb_test <- predict(xgb_fit, newdata = X_test_mat, type = "prob")[, "Yes"]
pred_xgb_test <- ifelse(prob_xgb_test >= 0.5, 1, 0)

acc_xgb <- mean(pred_xgb_test == y_test_bin)
roc_xgb <- roc(y_test_bin, prob_xgb_test)
auc_xgb <- as.numeric(auc(roc_xgb))
sse_xgb <- sum((y_test_bin - prob_xgb_test)^2)
f1_macro_xgb <- macro_f1(pred_xgb_test, y_test_bin)

acc_xgb; auc_xgb; f1_macro_xgb


```


```{r}
# SVM var importance

svm_vi <- varImp(svm_fit, scale = FALSE)
svm_imp_df <- as.data.frame(svm_vi$importance)
colnames(svm_imp_df)[1] <- "importance_raw"
svm_imp_df$feature <- rownames(svm_vi$importance)
svm_imp_df <- svm_imp_df[, c("feature", "importance_raw")]
svm_imp_df <- svm_imp_df[order(-svm_imp_df$importance_raw), ]
top10_svm  <- head(svm_imp_df, 10)
```


```{r}
# RF var importance

rf_vi <- varImp(rf_fit, scale = FALSE)
rf_imp_df <- as.data.frame(rf_vi$importance)
colnames(rf_imp_df)[1] <- "importance_raw"
rf_imp_df$feature <- rownames(rf_vi$importance)
rf_imp_df <- rf_imp_df[, c("feature", "importance_raw")]
rf_imp_df <- rf_imp_df[order(-rf_imp_df$importance_raw), ]
top10_rf  <- head(rf_imp_df, 10)
```

```{r}
# XGB var importance

xgb_vi <- varImp(xgb_fit, scale = FALSE)
xgb_imp_df <- as.data.frame(xgb_vi$importance)
colnames(xgb_imp_df)[1] <- "importance_raw"
xgb_imp_df$feature <- rownames(xgb_vi$importance)
xgb_imp_df <- xgb_imp_df[, c("feature", "importance_raw")]
xgb_imp_df <- xgb_imp_df[order(-xgb_imp_df$importance_raw), ]
top10_xgb  <- head(xgb_imp_df, 10)
```

```{r}
# Combined importance long format (for your later plots)

imp_svm <- top10_svm %>%
mutate(
model             = "SVM (Linear)",
importance_scaled = importance_raw / max(importance_raw),
importance_share  = importance_raw / sum(importance_raw)
)

imp_rf <- top10_rf %>%
mutate(
model             = "Random Forest",
importance_scaled = importance_raw / max(importance_raw),
importance_share  = importance_raw / sum(importance_raw)
)

imp_xgb <- top10_xgb %>%
mutate(
model             = "XGBoost",
importance_scaled = importance_raw / max(importance_raw),
importance_share  = importance_raw / sum(importance_raw)
)

imp_all_long <- bind_rows(imp_svm, imp_rf, imp_xgb)

```

```{r}
imp_all_long

```


```{r}
library(ggplot2)
library(pROC)
library(dplyr)
library(tidyr)

# ROC objects
roc_svm <- roc(y_test_bin, prob_svm_test)
roc_rf  <- roc(y_test_bin, prob_rf_test)
roc_xgb <- roc(y_test_bin, prob_xgb_test)

# Convert to data frames
roc_svm_df <- data.frame(
  fpr   = 1 - roc_svm$specificities,
  tpr   = roc_svm$sensitivities,
  model = "SVM (Linear)"
)

roc_rf_df <- data.frame(
  fpr   = 1 - roc_rf$specificities,
  tpr   = roc_rf$sensitivities,
  model = "Random Forest"
)

roc_xgb_df <- data.frame(
  fpr   = 1 - roc_xgb$specificities,
  tpr   = roc_xgb$sensitivities,
  model = "XGBoost"
)

roc_all <- bind_rows(roc_svm_df, roc_rf_df, roc_xgb_df)

ggplot(roc_all, aes(x = fpr, y = tpr, color = model)) +
  geom_line(size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "ROC Curves: SVM vs Random Forest vs XGBoost",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal()

```

```{r}
model_summary <- data.frame(
  Model = c("SVM (Linear)", "Random Forest", "XGBoost"),
  
  Accuracy = c(
    acc_svm,
    acc_rf,
    acc_xgb
  ),
  
  AUC = c(
    auc_svm,
    auc_rf,
    auc_xgb
  ),
  
  F1_Macro = c(
    f1_macro_svm,
    f1_macro_rf,
    f1_macro_xgb
  )
)

model_summary_pretty <- model_summary %>%
  mutate(
    Accuracy = round(Accuracy, 4),
    AUC      = round(AUC, 4),
    F1_Macro = round(F1_Macro, 4)
  )

model_summary_pretty


```


```{r}
calibration_df <- data.frame(
  y_true   = y_test_bin,
  svm_prob = prob_svm_test,
  rf_prob  = prob_rf_test,
  xgb_prob = prob_xgb_test
)

# Function to build calibration table
make_calib <- function(df, prob_col, model_name, n_bins = 10) {
  df %>%
    mutate(
      prob = .data[[prob_col]],
      bin  = cut(prob, breaks = seq(0, 1, length.out = n_bins + 1), include.lowest = TRUE)
    ) %>%
    group_by(bin) %>%
    summarise(
      mean_pred = mean(prob),
      obs_rate  = mean(y_true),
      n         = n(),
      .groups   = "drop"
    ) %>%
    mutate(model = model_name)
}

calib_svm <- make_calib(calibration_df, "svm_prob", "SVM (Linear)")
calib_rf  <- make_calib(calibration_df, "rf_prob",  "Random Forest")
calib_xgb <- make_calib(calibration_df, "xgb_prob", "XGBoost")

calib_all <- bind_rows(calib_svm, calib_rf, calib_xgb)

ggplot(calib_all, aes(x = mean_pred, y = obs_rate, color = model)) +
  geom_line() +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "Calibration Curves by Model",
    x = "Mean Predicted Probability (per bin)",
    y = "Observed Survival Rate"
  ) +
  theme_minimal()


```

```{r}
# Long format for density by model
prob_long <- data.frame(
  y_true   = y_test_bin,
  svm_prob = prob_svm_test,
  rf_prob  = prob_rf_test,
  xgb_prob = prob_xgb_test
) %>%
  pivot_longer(
    cols      = c(svm_prob, rf_prob, xgb_prob),
    names_to  = "model",
    values_to = "prob"
  ) %>%
  mutate(
    model = recode(model,
                   svm_prob = "SVM (Linear)",
                   rf_prob  = "Random Forest",
                   xgb_prob = "XGBoost")
  )

# Overall distributions by model
ggplot(prob_long, aes(x = prob, fill = model)) +
  geom_density(alpha = 0.4) +
  labs(
    title = "Distribution of Predicted Probabilities by Model",
    x = "Predicted Probability of Survival (Yes)",
    y = "Density"
  ) +
  theme_minimal()

# Distributions split by true class
prob_long$y_true_fac <- factor(prob_long$y_true, levels = c(0, 1),
                               labels = c("Deceased (0)", "Alive (1)"))

ggplot(prob_long, aes(x = prob, fill = model)) +
  geom_density(alpha = 0.4) +
  facet_wrap(~ y_true_fac, ncol = 1) +
  labs(
    title = "Predicted Probability Distributions by Outcome and Model",
    x = "Predicted Probability of Survival (Yes)",
    y = "Density"
  ) +
  theme_minimal()

```

```{r}
# imp_all_long should have: feature, model, importance_scaled
# If many features, filter to union of top something:
top_features <- imp_all_long %>%
  dplyr::group_by(feature) %>%
  dplyr::summarise(max_imp = max(importance_scaled), .groups = "drop") %>%
  dplyr::arrange(desc(max_imp)) %>%
  dplyr::slice(1:20) %>%
  dplyr::pull(feature)

imp_plot_df <- imp_all_long %>%
  filter(feature %in% top_features)

ggplot(imp_plot_df, aes(x = reorder(feature, importance_scaled), 
                        y = importance_scaled, fill = model)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "Standardized Variable Importance",
    x = "Feature",
    y = "Relative Importance (scaled within model)"
  ) +
  theme_minimal()

```

### PDP/ICE ###

```{r}
library(iml)
library(xgboost)
library(caret)

# data for iml
X_test_df <- as.data.frame(X_test_mat)

# prediction function for xgboost (returns prob of positive class)
predict_xgb_prob <- function(model, newdata) {
  mat <- unname(as.matrix(newdata))           # remove names to avoid feature-name check
  dm  <- xgboost::xgb.DMatrix(data = mat)
  predict(model, newdata = dm)               # for binary:logistic this is P(y = 1)
}

# iml Predictor object using the fitted xgboost model
xgb_predictor <- Predictor$new(
  model            = xgb_fit$finalModel,
  data             = X_test_df,
  y                = y_test_bin,
  predict.function = predict_xgb_prob
)

# top 4 important features from xgboost
xgb_vi <- varImp(xgb_fit, scale = FALSE)
xgb_imp_df <- as.data.frame(xgb_vi$importance)
xgb_imp_df$feature <- rownames(xgb_vi$importance)
xgb_imp_df <- xgb_imp_df[order(-xgb_imp_df[, 1]), ]
top_feats <- head(xgb_imp_df$feature, 4)

# PDP + ICE plots for the top 4 features
pdp_list <- lapply(top_feats, function(f) {
  FeatureEffect$new(
    predictor = xgb_predictor,
    feature   = f,
    method    = "pdp+ice"
  )
})

for (pd in pdp_list) {
  print(plot(pd))
}

```

## Model Comparison Table
```{r}
install.packages("kableExtra")
library(dplyr)
library(knitr)
library(kableExtra)

model_summary <- data.frame(
  Model = c("SVM (Linear)", "Random Forest", "XGBoost"),
  Accuracy = c(acc_svm, acc_rf, acc_xgb),
  AUC      = c(auc_svm, auc_rf, auc_xgb),
  F1_Macro = c(f1_macro_svm, f1_macro_rf, f1_macro_xgb)
)

model_summary_pretty <- model_summary %>%
  mutate(
    Accuracy = round(Accuracy, 4),
    AUC      = round(AUC, 4),
    F1_Macro = round(F1_Macro, 4)
  )

kable(model_summary_pretty, format = "html", caption = "Model Comparison: Performance Metrics") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```
